{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pithl\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "from tensorflow.keras.metrics import TopKCategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "df = pd.read_csv('cefr_leveled_texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi!\\nI've been meaning to write for ages and f...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>﻿It was not so much how hard people found the ...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Keith recently came back from a trip to Chicag...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Griffith Observatory is a planetarium, and...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-LRB- The Hollywood Reporter -RRB- It's offici...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  Hi!\\nI've been meaning to write for ages and f...    B2\n",
       "1  ﻿It was not so much how hard people found the ...    B2\n",
       "2  Keith recently came back from a trip to Chicag...    B2\n",
       "3  The Griffith Observatory is a planetarium, and...    B2\n",
       "4  -LRB- The Hollywood Reporter -RRB- It's offici...    B2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pithl\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\pithl\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\pithl\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\pithl\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "10/10 [==============================] - 14s 578ms/step - loss: 1.7882 - accuracy: 0.2142 - top_k_categorical_accuracy: 0.3916 - val_loss: 1.7781 - val_accuracy: 0.2977 - val_top_k_categorical_accuracy: 0.4114\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 6s 624ms/step - loss: 1.7534 - accuracy: 0.2736 - top_k_categorical_accuracy: 0.4745 - val_loss: 1.6465 - val_accuracy: 0.2609 - val_top_k_categorical_accuracy: 0.4649\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 10s 947ms/step - loss: 1.5243 - accuracy: 0.3423 - top_k_categorical_accuracy: 0.6142 - val_loss: 1.4458 - val_accuracy: 0.4047 - val_top_k_categorical_accuracy: 0.6120\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 9s 866ms/step - loss: 1.4398 - accuracy: 0.3699 - top_k_categorical_accuracy: 0.6510 - val_loss: 1.4318 - val_accuracy: 0.3913 - val_top_k_categorical_accuracy: 0.6488\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 9s 858ms/step - loss: 1.3596 - accuracy: 0.3556 - top_k_categorical_accuracy: 0.6770 - val_loss: 1.4035 - val_accuracy: 0.3043 - val_top_k_categorical_accuracy: 0.6522\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 8s 833ms/step - loss: 1.3011 - accuracy: 0.3808 - top_k_categorical_accuracy: 0.6962 - val_loss: 1.2838 - val_accuracy: 0.3880 - val_top_k_categorical_accuracy: 0.6890\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 7s 702ms/step - loss: 1.2267 - accuracy: 0.3900 - top_k_categorical_accuracy: 0.7155 - val_loss: 1.2553 - val_accuracy: 0.4649 - val_top_k_categorical_accuracy: 0.6890\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 8s 792ms/step - loss: 1.1439 - accuracy: 0.4494 - top_k_categorical_accuracy: 0.7925 - val_loss: 1.2304 - val_accuracy: 0.4247 - val_top_k_categorical_accuracy: 0.7391\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 10s 984ms/step - loss: 1.0645 - accuracy: 0.4912 - top_k_categorical_accuracy: 0.8435 - val_loss: 1.2198 - val_accuracy: 0.4649 - val_top_k_categorical_accuracy: 0.7525\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 7s 751ms/step - loss: 0.9867 - accuracy: 0.6142 - top_k_categorical_accuracy: 0.8494 - val_loss: 1.2038 - val_accuracy: 0.4883 - val_top_k_categorical_accuracy: 0.7759\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 1.2038 - accuracy: 0.4883 - top_k_categorical_accuracy: 0.7759\n",
      "Loss: 1.2038021087646484\n",
      "Accuracy: 0.4882943034172058\n",
      "Top-2 Accuracy: 0.7759197354316711\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the text data\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df['text'])\n",
    "sequences = tokenizer.texts_to_sequences(df['text'])\n",
    "data = pad_sequences(sequences, maxlen=200)\n",
    "\n",
    "# Convert the categories to one-hot encoded vectors\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(df['label'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000, 64, input_length=200))\n",
    "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2))  # another LSTM layer\n",
    "model.add(Dense(32, activation='relu'))  # a Dense layer\n",
    "model.add(Dense(len(lb.classes_), activation='softmax'))\n",
    "\n",
    "# Compile the model with the top-2 accuracy metric\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "              metrics=['accuracy', TopKCategoricalAccuracy(k=2)])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=128)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy, top_2_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Loss: {loss}\\nAccuracy: {accuracy}\\nTop-2 Accuracy: {top_2_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above model performs at accuracy 0.49 and top-2 accuracy of 0.78, suggesting that it would be beneficial to fine tune it substantially. Maybe a larger amount of added layers could be tested. There might be other types of models that perform better, such as a BERT model. There are a variety of other ways that a model like this might be improved and the current accuracy appears too low to meaningfully deploy it. However, a top-2 accuracy of 0.76 suggests that the category in most cases should not be more than one level off. Given that it is difficult to definitively assess an article's CEFR level and some articles may fall between two adjacent categories, it may be sufficient to increase the top-2 accuracy some more. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
